{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8c233b-83e4-4e70-a8be-701252c5cfbc",
   "metadata": {},
   "source": [
    "# RAG Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ab22f-bfc2-4d7a-b0f2-95ad808744ff",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6f4c98-9354-48e9-b8b4-e27ff5832138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from pypdf import PdfReader\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from langchain.llms import VertexAI\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain_community.embeddings import VertexAIEmbeddings\n",
    "\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from utils.helper_utils import word_wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b5b9c-928d-4abc-9e2c-58d9b9910415",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7637e6-4265-43f7-9e35-f1b086804fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read and extract text from pdf\n",
    "reader = PdfReader(\"data_similar/indonesia_personal_data_protection_googlecloud_whitepaper.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e614e3af-747a-4790-a06b-a18a7cc838d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#chunking\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016dbaff-665b-4021-8570-30eae4bc0885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#embedding\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"indonesia_personal_data_protection_googlecloud_whitepaper\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312d7d0d-e842-4f32-a0bf-73b9ac530f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8cf50-c7f0-4462-a9b2-b18275ffc992",
   "metadata": {},
   "source": [
    "## Prompt Setting and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48775203-7cd7-4c3f-a184-753a935a290b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_prompt(query, relevant_passage):\n",
    "    \"\"\"\n",
    "    This function constructs a formatted prompt (essentially a question and answer template) \n",
    "    to be used with a large language model.\n",
    "    Args : \n",
    "        query: The user's question that needs to be answered.\n",
    "        relevant_passage: A piece of text (potentially retrieved from a document) \n",
    "        that might be relevant to answering the query.\n",
    "    Returns:\n",
    "        The formatted prompt string that can be used with an LLM to generate an answer.\n",
    "    \"\"\"\n",
    "    # escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "    # escaped = \"\\n\\n\".join(relevant_passage)\n",
    "    prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "    Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "    However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "    strike a friendly and converstional tone. \\\n",
    "    If the passage is irrelevant to the answer, you may ignore it.\n",
    "    QUESTION: '{query}'\n",
    "    PASSAGE: '{relevant_passage}'\n",
    "    \n",
    "    ANSWER:\n",
    "    \"\"\").format(query=query, relevant_passage=relevant_passage)\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def remove_hyphens(text):\n",
    "    \"\"\"\n",
    "    This function is a simple text processing function that removes hyphens from a given text string.\n",
    "    Args:\n",
    "        text: The text string from which hyphens need to be removed.\n",
    "    Returns:\n",
    "        The new text string without hyphens.\n",
    "    \"\"\"\n",
    "    return re.sub(r'-', '', text)\n",
    "\n",
    "def augment_multiple_query(query, model, topic):\n",
    "    \"\"\"\n",
    "    This function generates additional related questions based on an original query, \n",
    "    likely using a large language model.\n",
    "    Args : \n",
    "        query: The original user query.\n",
    "        model: An instance of a GenerativeModel class \n",
    "        (likely a pre-trained LLM for generating text).\n",
    "        topic: The topic associated with the original query.\n",
    "    Returns :\n",
    "        A list of strings, where each string represents \n",
    "        a single augmented (related) question generated by the LLM.\n",
    "    \"\"\"\n",
    "    prompt = (\"\"\"Suggest up to five additional short, related questions to help them find the information they need, covering different aspects of the topic. Output one question per line. Do not hyphen or number the questions.\n",
    "    QUESTION: '{query}'\n",
    "    TOPIC: '{topic}'\n",
    "    \n",
    "    ANSWER:\n",
    "    \"\"\").format(query=query, topic=topic)\n",
    "    \n",
    "    model = GenerativeModel(model)\n",
    "    answer = model.generate_content(prompt)\n",
    "    \n",
    "    answer = answer.text\n",
    "    answer.split(\"\\n\")\n",
    "\n",
    "    clean_text = remove_hyphens(answer)\n",
    "    sentences = [line for line in clean_text.splitlines()]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def get_augment_multiple_rerank_retrived(original_query, model, topic, chroma_collection):\n",
    "    \"\"\"\n",
    "    This function takes an original query, leverages an LLM to generate related questions, \n",
    "    retrieves potentially relevant documents from a collection, \n",
    "    and re-ranks them based on their similarity to the original query.\n",
    "    Args : \n",
    "        original_query: The user's initial question.\n",
    "        model: An instance of a GenerativeModel class (likely a pre-trained LLM).\n",
    "        topic: The topic associated with the original query.\n",
    "        chroma_collection: A ChromaDB collection object that presumably stores documents or text data\n",
    "    \"\"\"\n",
    "    augmented_queries = augment_multiple_query(original_query, model, topic)\n",
    "    \n",
    "    queries = [original_query] + augmented_queries\n",
    "    results = chroma_collection.query(query_texts=queries, n_results=5)\n",
    "    \n",
    "    retrieved_documents = results['documents']\n",
    "    \n",
    "    unique_documents = set()\n",
    "    for documents in retrieved_documents:\n",
    "        for document in documents:\n",
    "            unique_documents.add(document)\n",
    "    \n",
    "    unique_documents = list(unique_documents)\n",
    "    \n",
    "    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    \n",
    "    pairs = []\n",
    "    for doc in unique_documents:\n",
    "        pairs.append([original_query, doc])\n",
    "        \n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    pairs = [[original_query, doc] for doc in unique_documents]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    sorted_indices = np.argsort(scores)[::-1].tolist()\n",
    "    reordered_list = sorted(unique_documents, key=lambda x: sorted_indices.index(unique_documents.index(x)))\n",
    "\n",
    "    return reordered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61737a9-e6ae-4418-8aba-cb47ce8f04cf",
   "metadata": {},
   "source": [
    "## Query test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b9fb0af-f3fa-4f45-9dfe-09dea47f96f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_query = \"what is indonesia pdp law?\"\n",
    "passage = get_augment_multiple_rerank_retrived(original_query, 'gemini-pro', 'Process', chroma_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b71202-7acb-479b-af75-cec7f61af14c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Indonesia Personal Data Protection Law (PDPL) was enacted on October 17, 2022. It regulates the collection, use, disclosure, storage, and disposal of personal data by organizations operating in Indonesia. The law aims to protect the privacy rights of individuals and ensure the responsible handling of personal data. The PDPL applies to organizations that process personal data of Indonesian citizens or residents, regardless of the location of the organization. It establishes obligations for organizations to obtain consent from individuals before collecting their personal data, to protect the data from unauthorized access or use, and to dispose of it securely when it is no longer needed. The PDPL also provides rights to individuals to access, correct, or delete their personal data, and to complain to the Indonesian Personal Data Protection Commission if they believe their rights have been violated."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = make_prompt(original_query, passage)\n",
    "model = GenerativeModel('gemini-pro')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4759791a-3834-443c-b1dc-794acfbedd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A 'controller' is a party that processes data on its own or together with others, in order to fulfill purposes it has designated. A 'processor' is a natural or legal person who processes personal data on behalf of the controller. The controller is legally responsible for compliance with the law, determining the purpose and means of processing, and ensuring that the processor acts in accordance with the controller's instructions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_query = \"what is controller and processor?\"\n",
    "passage = get_augment_multiple_rerank_retrived(original_query, 'gemini-pro', 'Process', chroma_collection)\n",
    "\n",
    "prompt = make_prompt(original_query, passage)\n",
    "model = GenerativeModel('gemini-pro')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d15edf6-a5de-460c-8de0-b3f3c723477f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I apologize, but I cannot provide an answer to your question based on the information provided in the passage. There is no specific mention of who enacted the pdp law."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_query = \"Who enacted the pdp law?\"\n",
    "passage = get_augment_multiple_rerank_retrived(original_query, 'gemini-pro', 'Process', chroma_collection)\n",
    "\n",
    "prompt = make_prompt(original_query, passage)\n",
    "model = GenerativeModel('gemini-pro')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
