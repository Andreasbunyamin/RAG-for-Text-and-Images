{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ac678-7eda-4bdf-aa9e-2d24e750db1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recommended to be updated on daily basis because of the fast development\n",
    "!pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09637c51-9870-44c9-a9c7-a6a44f2a7d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI\n",
    "import vertexai\n",
    "from code_secrets import cridentials\n",
    "\n",
    "# Replace with your project ID and region\n",
    "PROJECT_NAME = cridentials.get('PROJECT_NAME')\n",
    "LOCATION = cridentials.get('LOCATION')\n",
    "\n",
    "vertexai.init(project=PROJECT_NAME, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf3e20-b761-4014-b930-d4a817119a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI\n",
    "\n",
    "# temperature range from 0 to 1 and lower values mean more conservative\n",
    "# top_p range from 0 to 1 and lower values mean more conservative\n",
    "# top_k range from 0 to 40 and lower values mean more conservative\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name=\"gemini-pro\",\n",
    "    max_output_tokens=200,\n",
    "    temperature=0.3,\n",
    "    top_p=0.5,\n",
    "    top_k=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6542db4-63bb-435b-b5d9-890601b47faa",
   "metadata": {},
   "source": [
    "### Chroma Versions Approach (Works Partially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "74244016-09f4-4fdc-8fff-7fbb94b24c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helper_utils import word_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ccf97ad-0253-4d0a-bb16-885a3398c4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"indonesia_personal_data_protection_googlecloud_whitepaper.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79274ecc-9d66-450b-a608-7e56a95165f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a5b78d-da5d-4c16-9175-b3a337d9fb90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005ea129-7f81-4d23-9b6e-47b82d782baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4433b1d-7c17-479b-9636-8642739e568d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e32ac8-f4d6-4603-a226-f9b3a2d18ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Use to remove collection\n",
    "# chroma_client.delete_collection(\"Data_Governance_Data_Extermination_BAPD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8b21671-cdc9-48ac-9d57-86241f4a41b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"indonesia_personal_data_protection_googlecloud_whitepaper\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b7c59d-1a1a-481d-8e0e-a5417e3be6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What are the first process of BAPD?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42690750-bc1c-404d-b068-774021cac76c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI\n",
    "import vertexai\n",
    "from code_secrets import cridentials\n",
    "\n",
    "# Replace with your project ID and region\n",
    "PROJECT_NAME = cridentials.get('PROJECT_NAME')\n",
    "LOCATION = cridentials.get('LOCATION')\n",
    "\n",
    "vertexai.init(project=PROJECT_NAME, location=LOCATION)\n",
    "\n",
    "# temperature range from 0 to 1 and lower values mean more conservative\n",
    "# top_p range from 0 to 1 and lower values mean more conservative\n",
    "# top_k range from 0 to 40 and lower values mean more conservative\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name=\"gemini-pro\",\n",
    "    max_output_tokens=200,\n",
    "    temperature=0.3,\n",
    "    top_p=0.5,\n",
    "    top_k=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e3558-a3c1-4fd2-9a05-f7e2d735b78c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import warnings\n",
    "from pathlib import Path as p\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e15b5b-27b5-4446-875d-6cc3b08c3f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel, ChatSession\n",
    "\n",
    "model = GenerativeModel(\"gemini-pro\")\n",
    "chat = model.start_chat()\n",
    "\n",
    "def get_chat_response(chat: ChatSession, prompt: str, retrieved_documents=retrieved_documents) -> str:\n",
    "\n",
    "    parameters = {\n",
    "        \"temperature\": 0.3,  # Temperature controls the degree of randomness in token selection.\n",
    "        \"max_output_tokens\": 200,  # Token limit determines the maximum amount of text output.\n",
    "        \"top_p\": 0.5,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "        \"top_k\": 8,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "    }\n",
    "    \n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "    response = chat.send_message(prompt, generation_config={\"temperature\": 0})\n",
    "    return response.text\n",
    "\n",
    "prompt = \"Hello.\"\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f1d9b-a07f-4375-adb6-0e446aa80f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = get_chat_response(chat, prompt=query, retrieved_documents=retrieved_documents)\n",
    "\n",
    "print(word_wrap(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324f3560-470a-4dcf-accc-e73886c33298",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use Gemini Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6702380-66fe-4c78-88e4-23f4026bcedd",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/intro_multimodal_rag.ipynb\n",
    "\n",
    "https://github.com/karndeepsingh/ApplicationsBuildWithLLMs/blob/main/Langchain_With_Gemini_And_Build_RAG.ipynb\n",
    "\n",
    "https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-applications-with-vertex-ai-palm-2-models-and-langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e004a-def5-4b5c-90c6-f2328fed70c6",
   "metadata": {},
   "source": [
    "https://ai.google.dev/examples/vectordb_with_chroma\n",
    "\n",
    "https://ai.google.dev/examples/doc_search_emb\n",
    "\n",
    "https://colab.research.google.com/drive/1xdosZ6bScn5oHnFzGeReMCLXQWK7Inpf?usp=sharing\n",
    "\n",
    "https://python.langchain.com/docs/use_cases/question_answering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9b36244-2c66-4d5e-ab15-605f372a95de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from pypdf import PdfReader\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from langchain.llms import VertexAI\n",
    "from code_secrets import cridentials\n",
    "\n",
    "# Replace with your project ID and region\n",
    "PROJECT_NAME = cridentials.get('PROJECT_NAME')\n",
    "LOCATION = cridentials.get('LOCATION')\n",
    "\n",
    "vertexai.init(project=PROJECT_NAME, location=LOCATION)\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain_community.embeddings import VertexAIEmbeddings\n",
    "\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from helper_utils import word_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa5715fd-2ff0-4e56-b71a-9cda3a1c9466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = PdfReader(\"indonesia_personal_data_protection_googlecloud_whitepaper.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "405a3f81-140e-4721-a914-fbe8b94195e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c6faa60-54c7-4b46-8ba1-ec2ffd1403c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41f09b7a-4916-4a2f-8648-5ca4c3d69888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0057681-a871-4cf2-8867-d57c9a00bc68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use to remove collection\n",
    "chroma_client.delete_collection(\"indonesia_personal_data_protection_googlecloud_whitepaper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f384767c-e7d5-46e5-88f2-5096430cc7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_chroma_db(documents, name):\n",
    "    chroma_client = chromadb.Client()\n",
    "    db = chroma_client.create_collection(name=name, embedding_function=embedding_function())\n",
    "    for i, d in enumerate(documents):\n",
    "        db.add(\n",
    "            documents=d,\n",
    "            ids=str(i)\n",
    "        )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2f2975c-ef9e-49cb-bb6b-0f8c2f4b3197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"Data_Governance_Data_Extermination_BAPD\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf89cfdf-3328-4f72-a49e-c3c0e99e192b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>metadatas</th>\n",
       "      <th>documents</th>\n",
       "      <th>uris</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.08090899884700775, -0.02253359742462635, 0...</td>\n",
       "      <td>None</td>\n",
       "      <td>google cloud whitepaper mar ch 2023 i n d o n ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.02525135688483715, -0.03832373768091202, 0...</td>\n",
       "      <td>None</td>\n",
       "      <td>g o o g l e c l o u d t a b l e o f c o n t e ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>[-0.04223982244729996, -0.04441278055310249, 0...</td>\n",
       "      <td>None</td>\n",
       "      <td>p r o c e s s o r s ” ( “ p r o c e s s o r s ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ids                                         embeddings metadatas  \\\n",
       "0   0  [-0.08090899884700775, -0.02253359742462635, 0...      None   \n",
       "1   1  [-0.02525135688483715, -0.03832373768091202, 0...      None   \n",
       "2  10  [-0.04223982244729996, -0.04441278055310249, 0...      None   \n",
       "\n",
       "                                           documents  uris  data  \n",
       "0  google cloud whitepaper mar ch 2023 i n d o n ...  None  None  \n",
       "1  g o o g l e c l o u d t a b l e o f c o n t e ...  None  None  \n",
       "2  p r o c e s s o r s ” ( “ p r o c e s s o r s ...  None  None  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(chroma_collection.peek(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c43a0adc-0a85-43a9-bd66-457622fa5cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db):\n",
    "    passage = db.query(query_texts=[query], n_results=5)['documents'][0]\n",
    "    return passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9b82c39-81e8-4d11-8b6d-68e92f40be9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g o o g l e c l o u d e n u m e r a t e d s e t o f p r o c e s s i n g p r i n c i p l e s, i n c l u d i n g t h a t o r g a n i z a t i o n s m u s t n o t i f y d a t a s u b j e c t s o f t h e p u r p o s e s f o r w h i c h t h e y p r o c e s s p e r s o n a l d a t a, m u s t p r o c e s s p e r s o n a l d a t a i n a l i m i t e d, s p e c i ﬁ c, t r a n s p a r e n t, a n d l a w f u l m a n n e r, a n d m u s t pr otect the security of personal data fr om unauthoriz ed access, unauthoriz ed disclosur e, unauthoriz ed alter ation, misuse,', \"o y o u a b o u t y o u r d a t a y o u r d a t a i s c r i t i c a l t o y o u r b u s i n e s s, a n d y o u t a k e g r e a t c a r e t o k e e p i t s a f e a n d u n d e r y o u r c o n t r o l. w e w a n t y o u t o f e e l c o n ﬁ d e n t t h a t t a k i n g a d v a n t a g e o f g o o g l e w o r k s p a c e a n d g o o g l e c l o u d s e r v i c e s d o e sn't r e q u i r e y o u t o c o m p r o m i s e o n s e c u r i t y o r c o n t r o l o f y o u r\", 'g o o g l e c l o u d c o n c l u s i o n a t g o o g l e, w e r e c o g n i z e t h a t y o u r d a t a i s y o u r s o n l y a n d g u a r a n t e e i n g t h e p r i v a c y o f y o u r d a t a i s k e y. t h e p r o t e c t i o n o f y o u r d a t a i s a p r i m a r y d e s i g n c o n s i d e r a t i o n f o r a l l o u r i n f r a s t r u c t u r e, p r o d u c t s a n d p e r s o n n e l o p e r a t i o n s. w e b e l i e v e t h a t g o o g l e c a n o f f e r a l e v e l o f p r o t e c t i o', 'd a t a w e p r o c e s s a c c o r d i n g t o y o u r g o o g l e c l o u d a g r e e m e n t ( s ). 1 i n t h i s w h i t e p a p e r, “ y o u / y o u r ” r e f e r s t o g o o g l e c l o u d a n d g o o g l e w o r k s p a c e c u s t o m e r s a s w e l l a s g o o g l e c l o u d p a r t n e r s. u n l e s s i n d i c a t e d o t h e r w i s e, r e f e r e n c e s t o “ c u s t o m e r s ” w i l l i n c l u d e g o o g l e c l o u d p a r t n e r s a n d r e f e r e n c e s t o “ c u s t o m e r', 'g o o g l e c l o u d c o n t r o l o f r e s o u r c e p e r m i s s i o n s. f o r e x a m p l e, u s i n g c l o u d i d e n t i t y a n d a c c e s s m a n a g e m e n t, c u s t o m e r s c a n m a p j o b f u n c t i o n s t o g r o u p s a n d r o l e s s o u s e r s o n l y a c c e s s t h e d a t a t h e y n e e d t o g e t t h e j o b d o n e. f u r t h e r m o r e, c u s t o m e r s m a y d e l e t e c u s t o m e r d a t a f r o m o u r s y s t e m s o r t a k e i t w i t h t h e m i f t h']\n"
     ]
    }
   ],
   "source": [
    "# Perform embedding search\n",
    "passage = get_relevant_passage(\"Data Governance\", chroma_collection)\n",
    "print(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d14076a-67bf-4fbe-b45b-228966f05a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_prompt(query, relevant_passage):\n",
    "    # escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "    # escaped = \"\\n\\n\".join(relevant_passage)\n",
    "    prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "    Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "    However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "    strike a friendly and converstional tone. \\\n",
    "    If the passage is irrelevant to the answer, you may ignore it.\n",
    "    QUESTION: '{query}'\n",
    "    PASSAGE: '{relevant_passage}'\n",
    "    \n",
    "    ANSWER:\n",
    "    \"\"\").format(query=query, relevant_passage=relevant_passage)\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "471dd04c-ea8f-4e94-8910-2542c477e1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful and informative bot that answers questions using text from the reference passage included below.     Be sure to respond in a complete sentence, being comprehensive, including all relevant background information.     However, you are talking to a non-technical audience, so be sure to break down complicated concepts and     strike a friendly and converstional tone.     If the passage is irrelevant to the answer, you may ignore it.\n",
       "    QUESTION: 'What is indonesia pdp law?'\n",
       "    PASSAGE: '['g o o g l e c l o u d e n u m e r a t e d s e t o f p r o c e s s i n g p r i n c i p l e s, i n c l u d i n g t h a t o r g a n i z a t i o n s m u s t n o t i f y d a t a s u b j e c t s o f t h e p u r p o s e s f o r w h i c h t h e y p r o c e s s p e r s o n a l d a t a, m u s t p r o c e s s p e r s o n a l d a t a i n a l i m i t e d, s p e c i ﬁ c, t r a n s p a r e n t, a n d l a w f u l m a n n e r, a n d m u s t pr otect the security of personal data fr om unauthoriz ed access, unauthoriz ed disclosur e, unauthoriz ed alter ation, misuse,', \"o y o u a b o u t y o u r d a t a y o u r d a t a i s c r i t i c a l t o y o u r b u s i n e s s, a n d y o u t a k e g r e a t c a r e t o k e e p i t s a f e a n d u n d e r y o u r c o n t r o l. w e w a n t y o u t o f e e l c o n ﬁ d e n t t h a t t a k i n g a d v a n t a g e o f g o o g l e w o r k s p a c e a n d g o o g l e c l o u d s e r v i c e s d o e sn't r e q u i r e y o u t o c o m p r o m i s e o n s e c u r i t y o r c o n t r o l o f y o u r\", 'g o o g l e c l o u d c o n c l u s i o n a t g o o g l e, w e r e c o g n i z e t h a t y o u r d a t a i s y o u r s o n l y a n d g u a r a n t e e i n g t h e p r i v a c y o f y o u r d a t a i s k e y. t h e p r o t e c t i o n o f y o u r d a t a i s a p r i m a r y d e s i g n c o n s i d e r a t i o n f o r a l l o u r i n f r a s t r u c t u r e, p r o d u c t s a n d p e r s o n n e l o p e r a t i o n s. w e b e l i e v e t h a t g o o g l e c a n o f f e r a l e v e l o f p r o t e c t i o', 'd a t a w e p r o c e s s a c c o r d i n g t o y o u r g o o g l e c l o u d a g r e e m e n t ( s ). 1 i n t h i s w h i t e p a p e r, “ y o u / y o u r ” r e f e r s t o g o o g l e c l o u d a n d g o o g l e w o r k s p a c e c u s t o m e r s a s w e l l a s g o o g l e c l o u d p a r t n e r s. u n l e s s i n d i c a t e d o t h e r w i s e, r e f e r e n c e s t o “ c u s t o m e r s ” w i l l i n c l u d e g o o g l e c l o u d p a r t n e r s a n d r e f e r e n c e s t o “ c u s t o m e r', 'g o o g l e c l o u d c o n t r o l o f r e s o u r c e p e r m i s s i o n s. f o r e x a m p l e, u s i n g c l o u d i d e n t i t y a n d a c c e s s m a n a g e m e n t, c u s t o m e r s c a n m a p j o b f u n c t i o n s t o g r o u p s a n d r o l e s s o u s e r s o n l y a c c e s s t h e d a t a t h e y n e e d t o g e t t h e j o b d o n e. f u r t h e r m o r e, c u s t o m e r s m a y d e l e t e c u s t o m e r d a t a f r o m o u r s y s t e m s o r t a k e i t w i t h t h e m i f t h']'\n",
       "    \n",
       "    ANSWER:\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is indonesia pdp law?\"\n",
    "prompt = make_prompt(query, passage)\n",
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90dacefc-1c9a-4d31-8380-ce486594dba2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I apologize, but I can't answer that question. The text provided does not contain any information about 'Indonesia PDP law'."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GenerativeModel('gemini-pro')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fca677-73e7-417d-b66b-fb57f4cfdb23",
   "metadata": {},
   "source": [
    "### Combination with Chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770aca6a-7cde-4316-a9f0-4ef791d7e3dd",
   "metadata": {},
   "source": [
    "#### Expansion with generated answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "08f47cd7-e238-4f59-b301-d9c414b4ccaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = chroma_collection.get(include=['embeddings'])['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9ea3de3d-c895-412c-9eb8-03ca8fd60ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_hyphens(text):\n",
    "    return re.sub(r'-', '', text)\n",
    "\n",
    "def augment_multiple_query(query, model, topic):\n",
    "    prompt = (\"\"\"Suggest up to five additional short, related questions to help them find the information they need, covering different aspects of the topic. Output one question per line. Do not hyphen or number the questions.\n",
    "    QUESTION: '{query}'\n",
    "    TOPIC: '{topic}'\n",
    "    \n",
    "    ANSWER:\n",
    "    \"\"\").format(query=query, topic=topic)\n",
    "    \n",
    "    model = GenerativeModel(model)\n",
    "    answer = model.generate_content(prompt)\n",
    "    \n",
    "    answer = answer.text\n",
    "    answer.split(\"\\n\")\n",
    "\n",
    "    clean_text = remove_hyphens(answer)\n",
    "    sentences = [line for line in clean_text.splitlines()]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def get_augment_multiple_retrived(original_query, model, topic, chroma_collection):\n",
    "    \n",
    "    augmented_queries = augment_multiple_query(original_query, model, topic)\n",
    "    \n",
    "    queries = [original_query] + augmented_queries\n",
    "    results = chroma_collection.query(query_texts=queries, n_results=5)\n",
    "    \n",
    "    retrieved_documents = results['documents']\n",
    "    \n",
    "    unique_documents = set()\n",
    "    for documents in retrieved_documents:\n",
    "        for document in documents:\n",
    "            unique_documents.add(document)\n",
    "    \n",
    "    unique_documents = list(unique_documents)\n",
    "    \n",
    "    return unique_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8a04f44c-78fe-412f-ab5a-9bddbe6425cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' What is the signoff process for nonBusiness Users?',\n",
       " ' What are the different types of documents that need to be signed off on?',\n",
       " ' Who is responsible for obtaining signoffs?',\n",
       " ' What are the consequences of not obtaining a signoff?',\n",
       " ' What is the best way to track the status of signoffs?']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_query = \"After i got the signing of Business Users?, what are the next process\"\n",
    "augmented_queries = augment_multiple_query(original_query, 'gemini-pro', 'Process')\n",
    "\n",
    "augmented_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e70a1cad-1924-4640-8201-39c7f574a35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries = [original_query] + augmented_queries\n",
    "results = chroma_collection.query(query_texts=queries, n_results=5, include=['documents', 'embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e46e0f0b-0017-488d-8626-f02d3fa9402f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.................................................................. 3 1. environment and data assessment & bapd document drafting process................................... 4 2. data extermination & bapd document finalization process....................................................... 5 3. bapd document approval process................................................................',\n",
       " '................................................................................. iii general overview of data governance & policy sop................................................................................... 1 data extermination and bapd document creation sop.....................................................................',\n",
       " \"1 general overview of data governance & policy sop data governance sop ensure s that data is managed effectively throughout the project's lifecycle. this sop should include clear guidelines and responsibilities for managing data, starting from data collection until data retention and disposal in accordance with regulations. several activities will be detailed in their own sop : a ( data sharing request in the engagement phase ) and b ( data extermination and bapd creation process in the post - engagement phase ). in this document, the focus will be on data extermination and bapd creation process in the post - engagement phase, which is crucial for ensuring compliance with uu no 27 tahun 2022 after project deliverables are accepted. post - engagement phasedm governance dgo others ensure project closure and all deliverables are accepted request dgo to prepare berita acara penghapusan data ( bapd ) until sign off & data extermination\",\n",
       " '1. data roles and responsibility....................................................................................................... 2 2. key point of bapd......................................................................................................................... 2 data extermination and bapd document creation process......',\n",
       " '3 data extermination and bapd document creation process 1. environment and data assessment and bapd document drafting process in this process, all exported data from the business users ’ environment for the project will be listed to create a unique data list for each team member according to their roles, responsibility, and data conditions. these lists will form the basis for drafting bapd documents. 2. data extermination and bapd document finalization process completely exterminate project data outside the business users ’ environment that being used. this process will be conducted for project team by considering roles, responsibilities, and data conditions. afterward, the bapd document will be finalized based on the results of the data extermination process. 3. bapd document approval process & ropa creation once the bapd document is finalized and signed by the project team, business data stewards, and',\n",
       " '5 2. data extermination & bapd document finalization process attend not attend not approve approvebusiness users dm governance project team pm dgo 2 contact the pm to ask if business users prefer witness the data extermination process by themselves or through recording request to pmcontact business users to determine their preference for the data extermination process question business usersattend or not attend set up a meeting with dm governance, dgo, business users, and project teams meeting dateset up a meeting with dgo, and project teams meeting date request to project teamshare screen and remove any relevant databapd draft open and record the meeting explain breifly the importance of data extermination process request the project team to screen share and exterminate relevant datarequest dgo for a brief data extermination overview there is no relevant data leftend the meeting data extermination recording linkbapd draft data extermination',\n",
       " '6 3. bapd document approval process & ropa creation sme ( dept. head ) dm governance dgo project team pm business users 3 bapd document send an email to the project team with a bapd attachment and request signature bapd document signature request by emailsign the bapd document signed bapd documentcontact the pm to have the bapd document sent toand signed by the business users signed bapd document request to pmsend an email to the business users with a bapd attachment and request their signature signed bapd document signature request by emailsign the bapd document signed bapd documentcontact the pm to have the bapd document sent to and signed by the dept. head signed bapd document request to pm sign the bapd document finish bapd documentupload the bapd document to project sharepoint finish bapd documentupload the bapd document to dge sharepoint finishsend an email to sme adi with a bapd attachment and request signature signed bapd document signature request by email',\n",
       " 'approved by lead business data stewards from business users, it signifies the completion of the data processing activities for the project. since further process is not anticipated, a ropa ( record of processing activities ) document is now required to comprehensively track and record all processes conducted in the project related to data. some additional remarks. if there are any deviations from the sop. before making any decisions, please consult with the data governance team. each phase will be broken down in detail further down. access the detail sop diagram here : link',\n",
       " 'bu environment if the data resides in the bu environment, and access has been granted during the project, send an email to bu requesting the revocation of access for specific individuals at the end of the project. 2. key point of bapd please ensure the following points before sending the bapd document to relevant stakeholders for signature 1. contract number and date 2. bapd document number 3. project name 4. data list 5. name and role 6. a link to relevant information ( video, sharepoint, email, etc. )',\n",
       " 'gds or the user. gds data extermination process will be documented in bapd ( berita acara penghapusan data ), which serves as proof of the extermination process. the effective date of this sop is december 13, 2023 we sincerely appreciate your cooperation and dedication to upholding these standardized procedures. thank you. develop ed by data governance team faisyal fadilla ali hapsari wulandari made bagus hadi sanjaya approved by head of department data governance & enablement yosafat adi pamungkas s',\n",
       " 'ii revision history this section will trac k changes and revisions made to this sop, ensuring that it remains up to date and aligned with the requirements. version date description 1. 0 … aims to standardize and formalize the data extermination and bapd document process while ensuring compliance with uu pdp',\n",
       " 'recording link update the data extermination recording link in the bapd draft bapd draft approve or not approveupdate bapd draft in response to feedbackupdated bapd draft final review of bapd draft export bapd draft as pdf bapd document 3 * ) details can be found 1. 2 key point of bapd',\n",
       " 'request dgoprepare aberita acara penghapusan data ( bapd ) until sign off & data extermination ( 2 ) data extermination and bapd document finishbusiness users validation that the project is finished2 baccess the detail sop here : link'}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = results['documents']\n",
    "\n",
    "# Deduplicate the retrieved documents\n",
    "unique_documents = set()\n",
    "for documents in retrieved_documents:\n",
    "    for document in documents:\n",
    "        unique_documents.add(document)\n",
    "\n",
    "unique_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f3d383ce-2f65-4d51-8d0e-757a46723e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_query = \"Siapakah yang akan menang pemilu 2024\"\n",
    "passage = get_augment_multiple_retrived(original_query, 'gemini-pro', 'Process', chroma_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a1537214-32ce-489e-8517-258a555f13dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = make_prompt(original_query, passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6987b53c-3078-4385-a0a1-0a0224d8e106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but the document you shared does not contain any information about the winner of the 2024 election. Therefore, I can't answer your question."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GenerativeModel('gemini-pro')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ae92c-c905-4cec-a943-8eee6bd7c284",
   "metadata": {},
   "source": [
    "#### Re-ranking with Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ccb3216d-8773-4efb-9d3c-73a3f79ebbac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11b306f2b8540af91b441116694d07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4803083d844660b3dbb222da72577b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5dba359d6e4cad8ca6a5c3cd8f9a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973d8d3ff9d246128738103f26bc0f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346fff6f86cc40ad8b5aaefe543ee47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8ad96474-8ef7-4358-9235-6c0d577054f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_query = \"Siapakah yang akan menang pemilu 2024\"\n",
    "passage = get_augment_multiple_retrived(original_query, 'gemini-pro', 'Process', chroma_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "59796db3-5695-4a87-8382-5e586ec65fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for doc in passage:\n",
    "    pairs.append([original_query, doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "619756e4-fe4f-4614-9e4d-c79396699ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = cross_encoder.predict(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ce46788a-92c2-4c7e-8d18-ef2eb54d7a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "-10.023334\n",
      "-11.504522\n",
      "-10.65059\n",
      "-11.47018\n",
      "-11.017712\n",
      "-11.109238\n",
      "-11.392984\n",
      "-10.988883\n",
      "-11.515486\n"
     ]
    }
   ],
   "source": [
    "pairs = [[query, doc] for doc in passage]\n",
    "scores = cross_encoder.predict(pairs)\n",
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "85d5f4d6-af67-4053-9dce-282c9542a997",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ordering:\n",
      "1\n",
      "3\n",
      "8\n",
      "5\n",
      "6\n",
      "7\n",
      "4\n",
      "2\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(\"New Ordering:\")\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "90d08c6d-8108-44dd-95c9-a6058ed792fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_hyphens(text):\n",
    "    return re.sub(r'-', '', text)\n",
    "\n",
    "def augment_multiple_query(query, model, topic):\n",
    "    prompt = (\"\"\"Suggest up to five additional short, related questions to help them find the information they need, covering different aspects of the topic. Output one question per line. Do not hyphen or number the questions.\n",
    "    QUESTION: '{query}'\n",
    "    TOPIC: '{topic}'\n",
    "    \n",
    "    ANSWER:\n",
    "    \"\"\").format(query=query, topic=topic)\n",
    "    \n",
    "    model = GenerativeModel(model)\n",
    "    answer = model.generate_content(prompt)\n",
    "    \n",
    "    answer = answer.text\n",
    "    answer.split(\"\\n\")\n",
    "\n",
    "    clean_text = remove_hyphens(answer)\n",
    "    sentences = [line for line in clean_text.splitlines()]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def get_augment_multiple_rerank_retrived(original_query, model, topic, chroma_collection):\n",
    "    \n",
    "    augmented_queries = augment_multiple_query(original_query, model, topic)\n",
    "    \n",
    "    queries = [original_query] + augmented_queries\n",
    "    results = chroma_collection.query(query_texts=queries, n_results=5)\n",
    "    \n",
    "    retrieved_documents = results['documents']\n",
    "    \n",
    "    unique_documents = set()\n",
    "    for documents in retrieved_documents:\n",
    "        for document in documents:\n",
    "            unique_documents.add(document)\n",
    "    \n",
    "    unique_documents = list(unique_documents)\n",
    "    \n",
    "    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    \n",
    "    pairs = []\n",
    "    for doc in unique_documents:\n",
    "        pairs.append([original_query, doc])\n",
    "        \n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    pairs = [[query, doc] for doc in unique_documents]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    sorted_indices = np.argsort(scores)[::-1].tolist()\n",
    "    reordered_list = sorted(unique_documents, key=lambda x: sorted_indices.index(unique_documents.index(x)))\n",
    "\n",
    "    return reordered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "30a988db-9510-4835-9ede-3227d148eda8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_query = \"After i got the signing of Business Users?, what are the next process\"\n",
    "passage = get_augment_multiple_rerank_retrived(original_query, 'gemini-pro', 'Process', chroma_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e7264c58-d7de-427e-8152-080b8d6b799c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Following the signing of the Business Users, the next stage is to request the Project Manager to forward the Business Activity Processing Document (BAPD) document to the Department Head for signature. Once the Department Head signs the BAPD, it should be uploaded to both the Project SharePoint and DGE SharePoint. Finally, an email along with a BAPD attachment should be sent to SME ADI, requesting their signature."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = make_prompt(original_query, passage)\n",
    "model = GenerativeModel('gemini-pro')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be51cf2-6922-44e5-8811-e3cc329cbcb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### End Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178f7467-478c-45fe-be05-439c19a2df74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from pypdf import PdfReader\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from langchain.llms import VertexAI\n",
    "from code_secrets import cridentials\n",
    "\n",
    "# Replace with your project ID and region\n",
    "PROJECT_NAME = cridentials.get('PROJECT_NAME')\n",
    "LOCATION = cridentials.get('LOCATION')\n",
    "\n",
    "vertexai.init(project=PROJECT_NAME, location=LOCATION)\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain_community.embeddings import VertexAIEmbeddings\n",
    "\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from helper_utils import word_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62de217d-3b00-4071-959b-c9ebccb3c89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = PdfReader(\"indonesia_personal_data_protection_googlecloud_whitepaper.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a55f15-de9a-484a-96c5-8513c88b98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e543f284-646b-44df-bb51-6dff4b5837c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"indonesia_personal_data_protection_googlecloud_whitepaper\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9907b67a-ad66-4215-ac91-50c8bf4a67fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e552cb76-8a1b-4dbd-bed1-c7b504a0446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(query, relevant_passage):\n",
    "    # escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "    # escaped = \"\\n\\n\".join(relevant_passage)\n",
    "    prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "    Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "    However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "    strike a friendly and converstional tone. \\\n",
    "    If the passage is irrelevant to the answer, you may ignore it.\n",
    "    QUESTION: '{query}'\n",
    "    PASSAGE: '{relevant_passage}'\n",
    "    \n",
    "    ANSWER:\n",
    "    \"\"\").format(query=query, relevant_passage=relevant_passage)\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def remove_hyphens(text):\n",
    "    return re.sub(r'-', '', text)\n",
    "\n",
    "def augment_multiple_query(query, model, topic):\n",
    "    prompt = (\"\"\"Suggest up to five additional short, related questions to help them find the information they need, covering different aspects of the topic. Output one question per line. Do not hyphen or number the questions.\n",
    "    QUESTION: '{query}'\n",
    "    TOPIC: '{topic}'\n",
    "    \n",
    "    ANSWER:\n",
    "    \"\"\").format(query=query, topic=topic)\n",
    "    \n",
    "    model = GenerativeModel(model)\n",
    "    answer = model.generate_content(prompt)\n",
    "    \n",
    "    answer = answer.text\n",
    "    answer.split(\"\\n\")\n",
    "\n",
    "    clean_text = remove_hyphens(answer)\n",
    "    sentences = [line for line in clean_text.splitlines()]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def get_augment_multiple_rerank_retrived(original_query, model, topic, chroma_collection):\n",
    "    \n",
    "    augmented_queries = augment_multiple_query(original_query, model, topic)\n",
    "    \n",
    "    queries = [original_query] + augmented_queries\n",
    "    results = chroma_collection.query(query_texts=queries, n_results=5)\n",
    "    \n",
    "    retrieved_documents = results['documents']\n",
    "    \n",
    "    unique_documents = set()\n",
    "    for documents in retrieved_documents:\n",
    "        for document in documents:\n",
    "            unique_documents.add(document)\n",
    "    \n",
    "    unique_documents = list(unique_documents)\n",
    "    \n",
    "    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    \n",
    "    pairs = []\n",
    "    for doc in unique_documents:\n",
    "        pairs.append([original_query, doc])\n",
    "        \n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    pairs = [[original_query, doc] for doc in unique_documents]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    sorted_indices = np.argsort(scores)[::-1].tolist()\n",
    "    reordered_list = sorted(unique_documents, key=lambda x: sorted_indices.index(unique_documents.index(x)))\n",
    "\n",
    "    return reordered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af237064-866c-48c9-b556-f6692e4c51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"what is indonesia pdp law?\"\n",
    "passage = get_augment_multiple_rerank_retrived(original_query, 'gemini-pro', 'Process', chroma_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16099995-fb6c-4b45-893c-e02c6d91f93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Personal Data Protection Law of Indonesia (PDP Law), enforced on October 17, 2022, regulates the collection, processing, and responsible use of personal data within Indonesia. This law aims to protect the privacy of individuals and ensure that their personal information is handled in a lawful, fair, and accountable manner."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = make_prompt(original_query, passage)\n",
    "model = GenerativeModel('gemini-pro')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50feaa15-cd4d-4b5d-9039-1a988a5c6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"what is controller and processor?\"\n",
    "passage = get_augment_multiple_rerank_retrived(original_query, 'gemini-pro', 'Process', chroma_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c4e498c-8b73-4b55-9b2d-f22db00204a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I apologize, but the passage does not contain any information about controllers and processors. Therefore, I cannot answer your question."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = make_prompt(original_query, passage)\n",
    "model = GenerativeModel('gemini-pro')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ac70c-e4b7-45fc-85dc-6023603898ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "pdfagent",
   "name": "common-cpu.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m113"
  },
  "kernelspec": {
   "display_name": "pdfagent",
   "language": "python",
   "name": "pdfagent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
